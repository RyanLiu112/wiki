<!doctype html><html lang=zh class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Personal wiki"><meta name=author content="Runze Liu"><link href=https://ryanliu112.github.io/wiki/Math/Bayesian%20Optimization/ rel=canonical><link href=../../CS285/23.Challenges%20and%20Open%20Problems/ rel=prev><link href=../Optimal%20Transport/ rel=next><link rel=icon href=../../assets/images/favicon.png><meta name=generator content="mkdocs-1.4.3, mkdocs-material-9.1.15"><title>Bayesian Optimization - My-wiki</title><link rel=stylesheet href=../../assets/stylesheets/main.26e3688c.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.ecc896b0.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../css/extra.css><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#bayesian-optimization class=md-skip> 跳转至 </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=页眉> <a href=../.. title=My-wiki class="md-header__button md-logo" aria-label=My-wiki data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> My-wiki </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Bayesian Optimization </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_2 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg> </label> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to light mode" type=radio name=__palette id=__palette_2> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg> </label> </form> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=搜索 placeholder=搜索 autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg> </label> <nav class=md-search__options aria-label=查找> <a href=javascript:void(0) class="md-search__icon md-icon" title=分享 aria-label=分享 data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=清空当前内容 aria-label=清空当前内容 tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> 正在初始化搜索引擎 </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/RyanLiu112/wiki title=前往仓库 class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> RyanLiu112/wiki </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class=md-tabs aria-label=标签 data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../.. class=md-tabs__link> Wiki </a> </li> <li class=md-tabs__item> <a href=../../CS/%E3%80%90C%2B%2B%E3%80%91STL/ class=md-tabs__link> CS </a> </li> <li class=md-tabs__item> <a href=../../CS285/01.Introduction%20and%20Course%20Overview/ class=md-tabs__link> CS285 </a> </li> <li class=md-tabs__item> <a href=./ class="md-tabs__link md-tabs__link--active"> Math </a> </li> <li class=md-tabs__item> <a href=../../Offline%20RL/1.BCQ/ class=md-tabs__link> Offline RL </a> </li> <li class=md-tabs__item> <a href=../../Reinforcement%20Learning/1.Basis/ class=md-tabs__link> Reinforcement Learning </a> </li> <li class=md-tabs__item> <a href=../../Tools/Git/ class=md-tabs__link> Tools </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label=导航栏 data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title=My-wiki class="md-nav__button md-logo" aria-label=My-wiki data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg> </a> My-wiki </label> <div class=md-nav__source> <a href=https://github.com/RyanLiu112/wiki title=前往仓库 class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> RyanLiu112/wiki </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> Wiki </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex=0> CS <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> CS </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../CS/%E3%80%90C%2B%2B%E3%80%91STL/ class=md-nav__link> 【C++】STL </a> </li> <li class=md-nav__item> <a href=../../CS/%E3%80%90C%2B%2B%E3%80%91%E6%8E%92%E5%BA%8F/ class=md-nav__link> 【C++】排序 </a> </li> <li class=md-nav__item> <a href=../../CS/%E3%80%90C%2B%2B%E3%80%91%E6%95%B0%E7%BB%84/ class=md-nav__link> 【C++】数组 </a> </li> <li class=md-nav__item> <a href=../../CS/%E3%80%90C%2B%2B%E3%80%91%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/ class=md-nav__link> 【C++】栈和队列 </a> </li> <li class=md-nav__item> <a href=../../CS/%E3%80%90C%2B%2B%E3%80%91%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/ class=md-nav__link> 【C++】输入输出 </a> </li> <li class=md-nav__item> <a href=../../CS/%E3%80%90C%2B%2B%E3%80%91%E9%93%BE%E8%A1%A8/ class=md-nav__link> 【C++】链表 </a> </li> <li class=md-nav__item> <a href=../../CS/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/ class=md-nav__link> 动态规划 </a> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_8> <label class=md-nav__link for=__nav_2_8 id=__nav_2_8_label tabindex=0> 算法基础课 <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_8_label aria-expanded=false> <label class=md-nav__title for=__nav_2_8> <span class="md-nav__icon md-icon"></span> 算法基础课 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../CS/%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80%E8%AF%BE/%E7%AC%AC%E4%B8%80%E7%AB%A0%20%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/ class=md-nav__link> 第一章 基础算法 </a> </li> <li class=md-nav__item> <a href=../../CS/%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80%E8%AF%BE/%E7%AC%AC%E4%B8%89%E7%AB%A0%20%E6%90%9C%E7%B4%A2%E4%B8%8E%E5%9B%BE%E8%AE%BA/ class=md-nav__link> 第三章 搜索与图论 </a> </li> <li class=md-nav__item> <a href=../../CS/%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80%E8%AF%BE/%E7%AC%AC%E4%BA%8C%E7%AB%A0%20%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/ class=md-nav__link> 第二章 数据结构 </a> </li> <li class=md-nav__item> <a href=../../CS/%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80%E8%AF%BE/%E7%AC%AC%E4%BA%94%E7%AB%A0%20%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/ class=md-nav__link> 第五章 动态规划 </a> </li> <li class=md-nav__item> <a href=../../CS/%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80%E8%AF%BE/%E7%AC%AC%E5%85%AD%E7%AB%A0%20%E8%B4%AA%E5%BF%83/ class=md-nav__link> 第六章 贪心 </a> </li> <li class=md-nav__item> <a href=../../CS/%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80%E8%AF%BE/%E7%AC%AC%E5%9B%9B%E7%AB%A0%20%E6%95%B0%E5%AD%A6%E7%9F%A5%E8%AF%86/ class=md-nav__link> 第四章 数学知识 </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex=0> CS285 <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> CS285 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../CS285/01.Introduction%20and%20Course%20Overview/ class=md-nav__link> 01.Introduction and Course Overview </a> </li> <li class=md-nav__item> <a href=../../CS285/02.Supervised%20Learning%20of%20Behaviors/ class=md-nav__link> 02.Supervised Learning of Behaviors </a> </li> <li class=md-nav__item> <a href=../../CS285/03.PyTorch%20Tutorial/ class=md-nav__link> 03.PyTorch Tutorial </a> </li> <li class=md-nav__item> <a href=../../CS285/04.Introduction%20to%20Reinforcement%20Learning/ class=md-nav__link> 4. Introduction to Reinforcement Learning </a> </li> <li class=md-nav__item> <a href=../../CS285/05.Policy%20Gradients/ class=md-nav__link> 5. Policy Gradients </a> </li> <li class=md-nav__item> <a href=../../CS285/06.Actor-Critic%20Algorithms/ class=md-nav__link> 6. Actor-Critic Algorithms </a> </li> <li class=md-nav__item> <a href=../../CS285/07.Value%20Function%20Methods/ class=md-nav__link> 7. Value Function Methods </a> </li> <li class=md-nav__item> <a href=../../CS285/08.Deep%20RL%20with%20Q-Functions/ class=md-nav__link> 08.Deep RL with Q Functions </a> </li> <li class=md-nav__item> <a href=../../CS285/09.Advanced%20Policy%20Gradients/ class=md-nav__link> 09.Advanced Policy Gradients </a> </li> <li class=md-nav__item> <a href=../../CS285/10.Optimal%20Control%20and%20Planning/ class=md-nav__link> 10.Optimal Control and Planning </a> </li> <li class=md-nav__item> <a href=../../CS285/11.Model-Based%20Reinforcement%20Learning/ class=md-nav__link> 11.Model Based Reinforcement Learning </a> </li> <li class=md-nav__item> <a href=../../CS285/12.Model-Based%20Policy%20Learning/ class=md-nav__link> 12.Model Based Policy Learning </a> </li> <li class=md-nav__item> <a href=../../CS285/13.Exploration%20%28Part%201%29/ class=md-nav__link> 13.Exploration (Part 1) </a> </li> <li class=md-nav__item> <a href=../../CS285/14.Exploration%20%28Part%202%29/ class=md-nav__link> 14.Exploration (Part 2) </a> </li> <li class=md-nav__item> <a href=../../CS285/15.Offline%20Reinforcement%20Learning%20%28Part%201%29/ class=md-nav__link> 15.Offline Reinforcement Learning (Part 1) </a> </li> <li class=md-nav__item> <a href=../../CS285/16.Offline%20Reinforcement%20Learning%20%28Part%202%29/ class=md-nav__link> 16.Offline Reinforcement Learning (Part 2) </a> </li> <li class=md-nav__item> <a href=../../CS285/17.Reinforcement%20Learning%20Theory%20Basics/ class=md-nav__link> 17.Reinforcement Learning Theory Basics </a> </li> <li class=md-nav__item> <a href=../../CS285/18.Variational%20Inference%20and%20Generative%20Models/ class=md-nav__link> 18.Variational Inference and Generative Models </a> </li> <li class=md-nav__item> <a href=../../CS285/19.Connection%20between%20Inference%20and%20Control/ class=md-nav__link> 19.Connection between Inference and Control </a> </li> <li class=md-nav__item> <a href=../../CS285/20.Inverse%20Reinforcement%20Learning/ class=md-nav__link> 20.Inverse Reinforcement Learning </a> </li> <li class=md-nav__item> <a href=../../CS285/22.Meta-Learning%20and%20Transfer%20Learning/ class=md-nav__link> 22.Meta Learning and Transfer Learning </a> </li> <li class=md-nav__item> <a href=../../CS285/23.Challenges%20and%20Open%20Problems/ class=md-nav__link> 23.Challenges and Open Problems </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4 checked> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex=0> Math <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=true> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> Math </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> Bayesian Optimization <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> Bayesian Optimization </a> <nav class="md-nav md-nav--secondary" aria-label=目录> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> 目录 </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#bo class=md-nav__link> BO 是什么？ </a> </li> <li class=md-nav__item> <a href=#bo_1 class=md-nav__link> BO 的过程： </a> <nav class=md-nav aria-label="BO 的过程："> <ul class=md-nav__list> <li class=md-nav__item> <a href=#gaussian-process-gp class=md-nav__link> Gaussian Process (GP) </a> </li> <li class=md-nav__item> <a href=#surrogate-model class=md-nav__link> Surrogate Model </a> </li> <li class=md-nav__item> <a href=#acquisition-function class=md-nav__link> Acquisition Function </a> <nav class=md-nav aria-label="Acquisition Function"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#gaussian-process-upper-confidence-bound-gp-ucb class=md-nav__link> Gaussian Process-Upper Confidence Bound (GP-UCB) </a> </li> <li class=md-nav__item> <a href=#expected-improvement-ei class=md-nav__link> Expected Improvement (EI) </a> </li> <li class=md-nav__item> <a href=#predictive-entropy-search-pes-entropy-search-es class=md-nav__link> Predictive Entropy Search (PES) &amp; Entropy Search (ES) </a> </li> <li class=md-nav__item> <a href=#thompson-sampling-ts class=md-nav__link> Thompson Sampling (TS) </a> </li> <li class=md-nav__item> <a href=#probability-of-improvement-pi class=md-nav__link> Probability of Improvement (PI) </a> </li> <li class=md-nav__item> <a href=#knowledge-gradient-kg class=md-nav__link> Knowledge Gradient (KG) </a> </li> <li class=md-nav__item> <a href=#max-value-entropy-search class=md-nav__link> Max-Value Entropy Search </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#smbo class=md-nav__link> SMBO </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_1 class=md-nav__link> 例子 </a> </li> <li class=md-nav__item> <a href=#bo_2 class=md-nav__link> BO 的优点 </a> </li> <li class=md-nav__item> <a href=#_2 class=md-nav__link> 应用 </a> </li> <li class=md-nav__item> <a href=#_3 class=md-nav__link> 参考文献 </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../Optimal%20Transport/ class=md-nav__link> Optimal Transport </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5> <label class=md-nav__link for=__nav_5 id=__nav_5_label tabindex=0> Offline RL <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Offline RL </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Offline%20RL/1.BCQ/ class=md-nav__link> Off-Policy Deep Reinforcement Learning without Exploration (ICML'19) </a> </li> <li class=md-nav__item> <a href=../../Offline%20RL/2.BEAR/ class=md-nav__link> RL </a> </li> <li class=md-nav__item> <a href=../../Offline%20RL/3.Diffuser/ class=md-nav__link> RL </a> </li> <li class=md-nav__item> <a href=../../Offline%20RL/4.Decision%20Transformer/ class=md-nav__link> RL </a> </li> <li class=md-nav__item> <a href=../../Offline%20RL/5.Trajectory%20Transformer/ class=md-nav__link> RL </a> </li> <li class=md-nav__item> <a href=../../Offline%20RL/6.Dicision%20Diffuser/ class=md-nav__link> RL </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6> <label class=md-nav__link for=__nav_6 id=__nav_6_label tabindex=0> Reinforcement Learning <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_6_label aria-expanded=false> <label class=md-nav__title for=__nav_6> <span class="md-nav__icon md-icon"></span> Reinforcement Learning </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Reinforcement%20Learning/1.Basis/ class=md-nav__link> 强化学习基础 </a> </li> <li class=md-nav__item> <a href=../../Reinforcement%20Learning/2.Markov%20Decision%20Process/ class=md-nav__link> 马尔可夫决策过程 </a> </li> <li class=md-nav__item> <a href=../../Reinforcement%20Learning/3.Dynamic%20Programming/ class=md-nav__link> 动态规划 </a> </li> <li class=md-nav__item> <a href=../../Reinforcement%20Learning/4.Monte%20Carlo%20Methods/ class=md-nav__link> 蒙特卡罗 </a> </li> <li class=md-nav__item> <a href=../../Reinforcement%20Learning/5.Temporal-Difference%20Learning/ class=md-nav__link> 时序差分学习 </a> </li> <li class=md-nav__item> <a href=../../Reinforcement%20Learning/6.Deep%20Q-Learning/ class=md-nav__link> 深度 Q 网络 </a> </li> <li class=md-nav__item> <a href=../../Reinforcement%20Learning/7.Policy%20Gradient/ class=md-nav__link> 策略梯度 </a> </li> <li class=md-nav__item> <a href=../../Reinforcement%20Learning/8.Actor-Critic/ class=md-nav__link> RL </a> </li> <li class=md-nav__item> <a href=../../Reinforcement%20Learning/9.Imitation%20Learning/ class=md-nav__link> RL </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_7> <label class=md-nav__link for=__nav_7 id=__nav_7_label tabindex=0> Tools <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_7_label aria-expanded=false> <label class=md-nav__title for=__nav_7> <span class="md-nav__icon md-icon"></span> Tools </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Tools/Git/ class=md-nav__link> Git: fork 后的仓库如何与原仓库同步 </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a href="https://github.com/RyanLiu112/wiki/edit/master/docs/Math/Bayesian Optimization.md" title=编辑此页 class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4v-2m10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1 2.1 2.1Z"/></svg> </a> <a href="https://github.com/RyanLiu112/wiki/raw/master/docs/Math/Bayesian Optimization.md" title=查看本页的源代码 class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.15 8.15 0 0 1-1.23-2Z"/></svg> </a> <h1 id=bayesian-optimization>Bayesian Optimization<a class=headerlink href=#bayesian-optimization title="Permanent link">&para;</a></h1> <h2 id=bo>BO 是什么？<a class=headerlink href=#bo title="Permanent link">&para;</a></h2> <p>贝叶斯优化（Bayesian Optimization, BO）是一种用于黑盒函数（black-box function）全局优化的顺序设计策略，不需要预先假设任何函数形式。它通常用于优化评估成本昂贵的函数。</p> <p>Bayesian optimization is a technique for optimizing expensive, black-box functions that are expensive to evaluate. It is used to optimize a function by constructing a probabilistic model that represents the function and using this model to guide the search for the optimal solution. Bayesian optimization is commonly used in machine learning and data science applications where the goal is to optimize hyperparameters for a model.</p> <p>BO 包括三大元素：</p> <ul> <li><strong>Objective function</strong>：The function we want to optimize, which is typically a black-box function that is expensive to evaluate.</li> <li><strong>Surrogate model</strong>：A probabilistic model that approximates the objective function based on the evaluations of the function at different points.（训练模型拟合数据）</li> <li><strong>Acquisition function</strong>：A function that guides the search for the optimal solution by balancing exploration and exploitation.（选择下一个点）</li> </ul> <h2 id=bo_1>BO 的过程：<a class=headerlink href=#bo_1 title="Permanent link">&para;</a></h2> <p>The process begins by evaluating the objective function at a few initial points to create a dataset. Then, the surrogate model is fitted to this dataset. The acquisition function is used to select the next point to evaluate based on the current model. This process is repeated iteratively, with the model being updated after each evaluation, and the acquisition function guiding the search for the optimal solution.</p> <p>BO 的思路：</p> <p>假设我们有一个函数 <span class=arithmatex>\(f: \mathcal{X} \to \mathbb{R}\)</span>，我们需要在 <span class=arithmatex>\(x \subseteq \mathcal{X}\)</span> 中找到：</p> <div class=arithmatex>\[ x^* = \arg\max_{x\in\mathcal{X}} f(x) \]</div> <p>BO 可以看作一个 sequential decision-making problem（序列决策问题），需要进行好多轮 iterations 迭代，在每一轮 iteration <span class=arithmatex>\(t=1,\cdots,T\)</span> 中，我们选择 <span class=arithmatex>\(x_t\in\mathcal{X}\)</span>（例如一组神经网络的超参），然后 query <span class=arithmatex>\(f\)</span> 得到对应的 <span class=arithmatex>\(f(x_t)\)</span>，把这组 <span class=arithmatex>\((x_t, y_t)\)</span> 加入我们的数据集中，接着进行下一轮 iteration。</p> <p>BO 的核心问题是在每一轮 iteration 中选择观测哪一个 <span class=arithmatex>\(x_t\)</span>，在 BO 中通过优化 acquisition function <span class=arithmatex>\(\alpha_t\)</span> 来选择 <span class=arithmatex>\(x_t\)</span>，也就是 <span class=arithmatex>\(x_t=\arg\max_{x\in\mathcal{X}} \alpha_t(x)\)</span>。</p> <p>exploration-exploitation trade-off：在选择 <span class=arithmatex>\(x_t\)</span> 的时候，我们既想尝试之前没有尝试过的点（exploration），又想选择根据当前观测点预测的值比较小的点（exploitation），所以我们既需要知道 exploitation 所需的 <span class=arithmatex>\(f(x)\)</span>，又需要知道 exploration 所需的 uncertainty，这种情况下最适合的模型是高斯过程（Gaussian Process，GP）。</p> <h3 id=gaussian-process-gp>Gaussian Process (GP)<a class=headerlink href=#gaussian-process-gp title="Permanent link">&para;</a></h3> <p>假如我们现在已经进行了前 <span class=arithmatex>\(t-1\)</span> 轮 iteration，获取到的数据为 <span class=arithmatex>\(\mathcal{D}_{t-1}=\{(x_1,y_1),(x_2,y_2),\cdots,(x_{t-1},y_{t-1})\}\)</span>，此时 posterior mean 和 posterior variance 分别表示为 <span class=arithmatex>\(\mu_{t-1}(x)\)</span> 和 <span class=arithmatex>\(\sigma_{t-1}^2(x)\)</span>，分别可以理解为 exploitation 和 exploration 的信息。</p> <p>有了 posterior mean 和 posterior variance，我们就可以计算 acquisition function <span class=arithmatex>\(\alpha_t\)</span>。</p> <h3 id=surrogate-model>Surrogate Model<a class=headerlink href=#surrogate-model title="Permanent link">&para;</a></h3> <h3 id=acquisition-function>Acquisition Function<a class=headerlink href=#acquisition-function title="Permanent link">&para;</a></h3> <p>Acquisition function 主要包括：</p> <ul> <li>GP-UCB：基于 MAB 中的 UCB 算法提出，理论很完美，可以基于 MAB 推导</li> <li>Expected Improvement (EI)：应用非常广泛，很多时候效果很好</li> <li>Predictive Entropy Search (PES) &amp; Entropy Search (ES)：基于信息论的策略</li> <li>Thompson Sampling (TS)：从 MAB 迁移过来的算法，在 BO 中用的不多</li> <li>Probability of Improvement (PI)：经典算法，现在不常用</li> <li>Knowledge Gradient (KG)</li> <li>Max-Value Entropy Search：在 PES 的基础上，把 <span class=arithmatex>\(x^*\)</span> 的分布换成 <span class=arithmatex>\(y^*\)</span> 的分布</li> </ul> <h4 id=gaussian-process-upper-confidence-bound-gp-ucb>Gaussian Process-Upper Confidence Bound (GP-UCB)<a class=headerlink href=#gaussian-process-upper-confidence-bound-gp-ucb title="Permanent link">&para;</a></h4> <div class=arithmatex>\[ x_t=\arg\max_{x \in \mathcal{X}} \alpha_t(x) = \arg\max_{x \in \mathcal{X}} \mu_{t-1}(x) + \sqrt{\beta_t} \sigma_{t-1}(x) \]</div> <p><img alt=image-20230228170516440 src=../assets/image-20230228170516440.png></p> <figure> <figcaption>Figure 1. GP-UCB Algorithm</figcaption> </figure> <h4 id=expected-improvement-ei>Expected Improvement (EI)<a class=headerlink href=#expected-improvement-ei title="Permanent link">&para;</a></h4> <p>EI 假设没有 observation noise，每个 Iteration 都能直接观察到 <span class=arithmatex>\(f(x_t)\)</span>，而不是 <span class=arithmatex>\(y_t\)</span>。</p> <p>EI 的策略定义为：</p> <div class=arithmatex>\[ \begin{aligned} x_t &amp;= \arg\max_{x \in \mathcal{X}} \mathbb{E}_{f(x) \sim \mathcal{N}(\mu_{t-1}(x), \sigma_{t-1}^2(x))} [\max(f(x)-f_{t-1}^{+}, 0)] \\ &amp;=\arg \max _{x \in \mathcal{X}}(\mu_{t-1}(x)-f_{t-1}^{+}) \Phi(\frac{\mu_{t-1}(x)-f_{t-1}^{+}}{\sigma_{t-1}(x)}) + \sigma_{t-1}(x) \phi(\frac{\mu_{t-1}(x)-f_{t-1}^{+}}{\sigma_{t-1}(x)}) \end{aligned} \]</div> <h4 id=predictive-entropy-search-pes-entropy-search-es>Predictive Entropy Search (PES) &amp; Entropy Search (ES)<a class=headerlink href=#predictive-entropy-search-pes-entropy-search-es title="Permanent link">&para;</a></h4> <h4 id=thompson-sampling-ts>Thompson Sampling (TS)<a class=headerlink href=#thompson-sampling-ts title="Permanent link">&para;</a></h4> <h4 id=probability-of-improvement-pi>Probability of Improvement (PI)<a class=headerlink href=#probability-of-improvement-pi title="Permanent link">&para;</a></h4> <h4 id=knowledge-gradient-kg>Knowledge Gradient (KG)<a class=headerlink href=#knowledge-gradient-kg title="Permanent link">&para;</a></h4> <h4 id=max-value-entropy-search>Max-Value Entropy Search<a class=headerlink href=#max-value-entropy-search title="Permanent link">&para;</a></h4> <h3 id=smbo>SMBO<a class=headerlink href=#smbo title="Permanent link">&para;</a></h3> <p><strong>Sequential Model-based Optimization (SMBO)</strong> 是贝叶斯优化的最简形式</p> <p>Problem Formulation：</p> <p>假设搜索空间为 <span class=arithmatex>\(\mathcal{X}\)</span>，<span class=arithmatex>\(\mathcal{D}\)</span> 是由数据对 <span class=arithmatex>\((\mathbf{x}_i, y_i)\)</span> 组成的数据集，</p> <h2 id=_1>例子<a class=headerlink href=#_1 title="Permanent link">&para;</a></h2> <p>假如现在</p> <h2 id=bo_2>BO 的优点<a class=headerlink href=#bo_2 title="Permanent link">&para;</a></h2> <h2 id=_2>应用<a class=headerlink href=#_2 title="Permanent link">&para;</a></h2> <h2 id=_3>参考文献<a class=headerlink href=#_3 title="Permanent link">&para;</a></h2> <p>贝叶斯优化/Bayesian Optimization - 贝叶斯有话的文章 - 知乎 <a href=https://zhuanlan.zhihu.com/p/76269142>https://zhuanlan.zhihu.com/p/76269142</a></p> <p>一文看懂贝叶斯优化/Bayesian Optimization - 多多笔记的文章 - 知乎 <a href=https://zhuanlan.zhihu.com/p/359392849>https://zhuanlan.zhihu.com/p/359392849</a></p> <p><a href=https://en.wikipedia.org/wiki/Bayesian_optimization>https://en.wikipedia.org/wiki/Bayesian_optimization</a></p> <p><a href=https://www.cnblogs.com/marsggbo/p/9866764.html>https://www.cnblogs.com/marsggbo/p/9866764.html</a></p> <p>Srinivas, N., et. al. Gaussian process optimization in the bandit setting: No regret and experimental design. ICML 2010.</p> </article> </div> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg> 回到页面顶部 </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=页脚> <a href=../../CS285/23.Challenges%20and%20Open%20Problems/ class="md-footer__link md-footer__link--prev" aria-label="上一页: 23.Challenges and Open Problems" rel=prev> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> 上一页 </span> <div class=md-ellipsis> 23.Challenges and Open Problems </div> </div> </a> <a href=../Optimal%20Transport/ class="md-footer__link md-footer__link--next" aria-label="下一页: Optimal Transport" rel=next> <div class=md-footer__title> <span class=md-footer__direction> 下一页 </span> <div class=md-ellipsis> Optimal Transport </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2023 Runze Liu </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../..", "features": ["content.action.edit", "content.action.view", "content.code.annotate", "content.code.copy", "content.tooltips", "navigation.footer", "navigation.indexes", "navigation.instant", "navigation.sections", "navigation.tabs", "navigation.top", "search.highlight", "search.share", "search.suggest", "toc.follow", "toc.integrate"], "search": "../../assets/javascripts/workers/search.208ed371.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script> <script src=../../assets/javascripts/bundle.b4d07000.min.js></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=../../javascripts/config.js></script> </body> </html>